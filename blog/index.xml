<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on 持续交付 2.0</title>
    <link>http://www.continuousdelivery20.com/blog/</link>
    <description>Recent content in Blogs on 持续交付 2.0</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Feb 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://www.continuousdelivery20.com/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>移动应用开发方面，Etsy的持续交付流水线探索</title>
      <link>http://www.continuousdelivery20.com/blog/2014/02/28/etsy-mobile-cd/</link>
      <pubDate>Fri, 28 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>http://www.continuousdelivery20.com/blog/2014/02/28/etsy-mobile-cd/</guid>
      <description>在很久以前，本站报导过Etsy如何实现Web端每日在生产环境上部署40次。现在移动应用大潮来了，它又是如何做的呢？本文发表于2014年2月，虽然有一些迟了，但相信对广大读者还是会有很多启发，也会带来更大的信心。
移动app的好评在用户转化率和品牌树立方面都有非常积极的帮助。相反，差评可能会有非常严重的后果。正如很多人所说：“移动应用的死活取决于它在应用市场中评分”
上面这个图是Etsy iOS应用的一个真实反馈。做为Etsy的开发人员，看到它真的很沮丧，但它是事实：有一些bug会从我们的指缝溜走，却被用户发现。对于Web端开发，我们使用我们的持续交付常规武器（从一些传统软件公司看来，可能是核武器）作为安全网来快速解决那些溜达到生产环境中的bug。然而，移动应用的发布需要第三方的审核（应用商店），平均耗时５天以上。
即使审核通过，是否升级，什么时候升级都是用户自己说的算——他们可能一直停留在某个旧版本上。根据我们的分析数据，Etsy目前有5个iOS版本和10个Android版本被用户使用。
通过持续集成 （Continuous Integration ，通常简称CI），我们能够在项目的开发和测试阶段发现并修复大部分问题，不至于影响到用户的体验：本文揭示Etsy对安卓和iOS应用实现持续集成流水线的过程。
每次提交(git push)都要在主干上，并在集成服务器上构建。 这是持续集成的第一基本原则，也是问题一旦被引入，能够快速发现的第一步：编译失败。在IDE里构建我们的应用并不算持续集成。感谢上帝，iOS和Android都是命令行友好的：构建iOS应用只要一个简单的命令：
xcodebuild -scheme &amp;quot;Etsy&amp;quot; archive 准备持续集成的环境 用于集成的机器应该与开发者的机器分开——它们要为构建和测试提供一个稳定、受控、可再生的环境。“确保所有用于集成的机器都是幂等的”这一点至关重要。为了确保统一性和可扩展性，使用一个环境准备(provisioning)的框架来管理所有的依赖是一个不错的方法。
在Etsy，我们很高兴用Chef来管理我们的基础设施 – 我们用它来准备我们的Mac Mini机器集合。在安装包管理的homebrew以及方便管理ruby环境的rbenv帮助下，我们的系统运维师Jon Cowie 施了一点点hdiutil小魔法(来管理disk images），我们的cookbooks也就准备好了。对于我们构建和运行测试所需安装的Xcode，Git，以及所有Android包来说，其中95%的工作，我们已经通过编程方式实现安装了，还有一些步骤需要手工完成。
另外，如果你与iOS provisioning profiles打过交道，一定能体会到，对它的管理和更新是多么烦人；假如有一个集中式系统，来管理所有的profiles，那能为工程师节省很多时间。
Building on push and providing daily deploys 把我们的CI机器与Jenkins服务器联动起来，安排一个计划让它每次git　push操作时都进行构建，这是小菜一碟。事情非常容易。但正是这么一个简单的步骤，每个星期可以帮助我们发现几次提交时忘记了某个文件，或编译问题——通过IRC或邮件，开发人员会得到通知，这样，这类问题在被发现几分钟内就会得到解决。除了push后立即构建app，我们还提供每日构建包，任何一个Etsy员工都可以把这个每日构建包安装到他们的移动设备上——这是“吃自己狗食”的精髓。促进我们的同事安装预发布版本的简单方法就是在他们使用官方发布版本时提醒（骚扰）他们。
测试 对于iOS设备，有七种不同的iPad，五种iPhone，还有iPod，当说到Android时，那就更不用说了，简直是多如牛毛，即便是只关注主流设备也没能少到哪里去。CI的目标是：问题一旦被引入，就立即发现：我们不能依靠测试团队在每次代码提交时，都一遍又一遍的验证同样的功能特性!
在Web端，我们已经有大量的测试集，这是我们引以为豪的，而且TDD文化已经形成。基本上，我们的移动应用也借用很多web端的代码库来提供内容：数据通过API获取，而且很多页面也是web views。移动应用的大多数核心逻辑依赖于UI层，这可能通过功能测试来覆盖。正因如此，我们第一个方法是聚焦于一些功能性测试，其前提是我们的API已经在Web端被测试过了（通过单元测试和冒烟测试）。
移动应用的功能性测试并不是新鲜事情，选择性也非常广泛。在我们公司，我们用Calabash 和Cucumber。Cucumber的友好格式和预定义步骤，加上Calabash，让测试团队自己就可以写测试，非无需移动应用开发工程师的帮助。
到目前为止，我们的功能测试运行在iPad/iPhone iOS 6和iOS7 以及Android上，覆盖我们第一层级的功能，包括:
 搜索列表和商店 注册新用户 用信用卡或礼品卡买东西  功能测试会模拟一个真正用户的使用步骤，所以这些测试需要某种假设的资源一定存在。比如在结算测试这个例子上，这些资源就包括:
 一个专门用于测试的买家帐户 一个专用于测试的卖家帐户 一个与帐户已关联好的信用卡  而我们的结算测试包括：
 用买家帐户在移动应用上登录 搜索某种商品（在卖家帐户的商铺里） 把它加到购物车 用信用卡支付  一旦测试结束，在后台就会有一个机制触发，用来取消这次交易，把该信用卡重置。
我们的功能性测试发现了bug，下面就是在iPad上的一个例子：
我们的注册测试导向了这个页面，并填写了所有的可见字段。然后，测试走到了先择 “Female“, “Male”和“Rather Not Say”这一步；在这个例子中，测试失败了（因为没有“male”选项）。</description>
    </item>
    
    <item>
      <title>移动应用开发方面，Etsy的持续交付流水线探索</title>
      <link>http://www.continuousdelivery20.com/blog/2013/06/13/etsy-pci-cd/</link>
      <pubDate>Thu, 13 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>http://www.continuousdelivery20.com/blog/2013/06/13/etsy-pci-cd/</guid>
      <description>Etsy是以手工艺成品买卖为主要特色，曾被纽约时报拿来和eBay，Amazon比较，被誉为“祖母的地下室收藏”。
移动app的好评在用户转化率和品牌树立方面都有非常积极的帮助。相反，差评可能会有非常严重的后果。正如很多人所说：“移动应用的死活取决于它在应用市场中评分”
上面这个图是Etsy iOS应用的一个真实反馈。做为Etsy的开发人员，看到它真的很沮丧，但它是事实：有一些bug会从我们的指缝溜走，却被用户发现。对于Web端开发，我们使用我们的持续交付常规武器（从一些传统软件公司看来，可能是核武器）作为安全网来快速解决那些溜达到生产环境中的bug。然而，移动应用的发布需要第三方的审核（应用商店），平均耗时５天以上。
即使审核通过，是否升级，什么时候升级都是用户自己说的算——他们可能一直停留在某个旧版本上。根据我们的分析数据，Etsy目前有5个iOS版本和10个Android版本被用户使用。
通过持续集成 （Continuous Integration ，通常简称CI），我们能够在项目的开发和测试阶段发现并修复大部分问题，不至于影响到用户的体验：本文揭示Etsy对安卓和iOS应用实现持续集成流水线的过程。
每次提交(git push)都要在主干上，并在集成服务器上构建。 这是持续集成的第一基本原则，也是问题一旦被引入，能够快速发现的第一步：编译失败。在IDE里构建我们的应用并不算持续集成。感谢上帝，iOS和Android都是命令行友好的：构建iOS应用只要一个简单的命令：
xcodebuild -scheme &amp;quot;Etsy&amp;quot; archive 准备持续集成的环境 用于集成的机器应该与开发者的机器分开——它们要为构建和测试提供一个稳定、受控、可再生的环境。“确保所有用于集成的机器都是幂等的”这一点至关重要。为了确保统一性和可扩展性，使用一个环境准备(provisioning)的框架来管理所有的依赖是一个不错的方法。
在Etsy，我们很高兴用Chef来管理我们的基础设施 – 我们用它来准备我们的Mac Mini机器集合。在安装包管理的homebrew以及方便管理ruby环境的rbenv帮助下，我们的系统运维师Jon Cowie 施了一点点hdiutil小魔法(来管理disk images），我们的cookbooks也就准备好了。对于我们构建和运行测试所需安装的Xcode，Git，以及所有Android包来说，其中95%的工作，我们已经通过编程方式实现安装了，还有一些步骤需要手工完成。
另外，如果你与iOS provisioning profiles打过交道，一定能体会到，对它的管理和更新是多么烦人；假如有一个集中式系统，来管理所有的profiles，那能为工程师节省很多时间。
Building on push and providing daily deploys 把我们的CI机器与Jenkins服务器联动起来，安排一个计划让它每次git　push操作时都进行构建，这是小菜一碟。事情非常容易。但正是这么一个简单的步骤，每个星期可以帮助我们发现几次提交时忘记了某个文件，或编译问题——通过IRC或邮件，开发人员会得到通知，这样，这类问题在被发现几分钟内就会得到解决。除了push后立即构建app，我们还提供每日构建包，任何一个Etsy员工都可以把这个每日构建包安装到他们的移动设备上——这是“吃自己狗食”的精髓。促进我们的同事安装预发布版本的简单方法就是在他们使用官方发布版本时提醒（骚扰）他们。
测试 对于iOS设备，有七种不同的iPad，五种iPhone，还有iPod，当说到Android时，那就更不用说了，简直是多如牛毛，即便是只关注主流设备也没能少到哪里去。CI的目标是：问题一旦被引入，就立即发现：我们不能依靠测试团队在每次代码提交时，都一遍又一遍的验证同样的功能特性!
在Web端，我们已经有大量的测试集，这是我们引以为豪的，而且TDD文化已经形成。基本上，我们的移动应用也借用很多web端的代码库来提供内容：数据通过API获取，而且很多页面也是web views。移动应用的大多数核心逻辑依赖于UI层，这可能通过功能测试来覆盖。正因如此，我们第一个方法是聚焦于一些功能性测试，其前提是我们的API已经在Web端被测试过了（通过单元测试和冒烟测试）。
移动应用的功能性测试并不是新鲜事情，选择性也非常广泛。在我们公司，我们用Calabash 和Cucumber。Cucumber的友好格式和预定义步骤，加上Calabash，让测试团队自己就可以写测试，非无需移动应用开发工程师的帮助。
到目前为止，我们的功能测试运行在iPad/iPhone iOS 6和iOS7 以及Android上，覆盖我们第一层级的功能，包括:
 搜索列表和商店 注册新用户 用信用卡或礼品卡买东西  功能测试会模拟一个真正用户的使用步骤，所以这些测试需要某种假设的资源一定存在。比如在结算测试这个例子上，这些资源就包括:
 一个专门用于测试的买家帐户 一个专用于测试的卖家帐户 一个与帐户已关联好的信用卡  而我们的结算测试包括：
 用买家帐户在移动应用上登录 搜索某种商品（在卖家帐户的商铺里） 把它加到购物车 用信用卡支付  一旦测试结束，在后台就会有一个机制触发，用来取消这次交易，把该信用卡重置。
我们的功能性测试发现了bug，下面就是在iPad上的一个例子：
我们的注册测试导向了这个页面，并填写了所有的可见字段。然后，测试走到了先择 “Female“, “Male”和“Rather Not Say”这一步；在这个例子中，测试失败了（因为没有“male”选项）。</description>
    </item>
    
    <item>
      <title>IMVU如何在实施持续部署的同时确保软件质量</title>
      <link>http://www.continuousdelivery20.com/blog/2010/04/09/imvu-cd-with-high-quality/</link>
      <pubDate>Fri, 09 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>http://www.continuousdelivery20.com/blog/2010/04/09/imvu-cd-with-high-quality/</guid>
      <description>在科技圈的各种大会上，我们和很多人有过交谈，他们对我们在IMVU上的持续部署流程很感兴趣，想知道我们是如何每天部署50次代码的。我们也听到一些问题，关于我们是如何做到在不引入新缺陷和回归问题的情况下使用这种方法，以及我们是如何在这样快节奏的环境中保障质量的。
事实是我们有时候也会因为抢速度而对顾客造成一些负面影响，而这些特性也是我们学到教训的来源。有时候我们做出的特性对于顾客没有什么价值，有时候会在生产环境中引入一些回归问题或是新的缺陷。
但是同时，我们小心翼翼做出的特性客户也曾经并不感冒——而这实际上耗费更多，因为我们花了更多的时间来学习和改变方向。举一个例子，我们曾经用了一个月的开发时间忙活一个叫做“更新”的特性——有点像Facebook的“Friend feed”（朋友新鲜事），而用户使用这个特性的方法和我们预估的完全不同。我们花了很长的时间交付了一个没有人需要的功能，而结果就是这延后了一个更加重要特性的交付，那就是：群组。
问问用户他们想要什么，节省了内部产品开发讨论的时间，使解决很多问题变得简单，“我们应该做一些工具让用户把阿凡达装备分类，还是直接做一个搜索工具，还是两个都做？”我们会在已有客户数据、竞争分析以及综合经验的基础上做一个尽量好的决定——然后尽快地做出一个功能，用客户来验证我们是否正确。
我们还发现在这过程中的代价——主要是缺陷和不太精细但是好用的特性——是值得的，这是因为我们能从顾客那里尽快得到关于产品创意的第一手反馈。一旦从客户那里得到反馈，就可以确定我们关于产品的设想和决策是否正确，我们也就能够更快地改变路线或是在一个好创意上增加投入。
你觉得我们并不担心如何给客户提供高质量的特性，或是他们的用户体验会受到影响吗？我们担心得不得了。
首先，我们很重视自动测试。这种对于测试和其框架的重视是我们如何架构QA团队和其使用方法的核心。我们的前CTO，也是IMVU的联合创始人Eric Ries曾经详细地描述过我们用来支持持续部署的基础设施，这里概括一下，我们是这么做的：
每一行提交代码都用一个持续集成服务器（Buildbot）运行监控自动测试 为了确保出问题的时候不让新代码加入代码库需要运行一个源控制提交检查 为了保障万无一失，需要在部署软件到集群时加一个脚本。我们编写了一个集群免疫系统来监测和对严重的回归问题发出警告，当发生错误时，自动回滚到上一个好的版本 如果错误不小心加入到了部署过程中，实时监控和警报会在第一时间通知团队 根因分析（五个为什么）可以驱动部署和产品开发流程中的不断改善 这个框架和自动测试就意味着软件工程师必须为我们编写的每行代码都编写测试。我们并没有一个单独的角色来编写测试和研究基础设施——这个工作是由整个工程团队承担的，这是能保持QA团队精简的原因。但是用这样的方法也不能防止所有的回归问题和缺陷。有一些用户使用实例，而有一些实例过于边缘，复杂到无法使用自动化的测试。活生生的人还是比可以做多维、多层测试的机器要聪明。我们的QA工程师依靠他们的洞察力和经验在实战中发现潜在的问题，他们用客户可能使用的方法来使用并且测试特性。
QA工程师会用几乎一半的时间手动测试特性。一旦发现测试实例可以自动化，我们就会把它加入到测试覆盖范围（在Scrum流程中，其中的一个环节可以确保我们能够捕捉到了这类测试用例）。在Scrum流程中有一步要求工程师向另一个成员展示特性，——其实就是在有人在场的情况下，做一些基本的手动测试。因为我们需要构造的特性比QA工程师有时间测试的要多得多，这就使得团队必须要做一些权益取舍，回答这样的问题：“哪些特性值得QA花时间来做？”有时候这个问题不是那么容易回答的，也使得团队开始考虑是不是应该让其他成员，甚至是整个公司加入到更有组织更有规模的测试环节中来。当我们觉得这是行得通的时候，QA工程师就会组织这样的测试环节，帮助团队更快地发现和分类问题。
我们的QA工程师还有两个更重要的责任。第一个就是Scrum计划流程中的重要组成部分，编写测试计划并和产品所有者和技术带头人一起做评估。这能确保重要客户的用例没有被遗漏，而且保证工程团队知道特性将怎么测试。也就是说，QA工程师帮助整个团队认识到顾客会如何使用他们正在搭建的特性。
第二个责任就是大家众所周知的QA工程师在敏捷环境中的作用：他们在特性开发阶段就和软件工程师一起工作，同时尽量多地测试进程中的特性并和整个团队面对面地讨论这些特性。当功能最终应该“交由QA处理”的时候，它们实际上已经被测试过了，而且很多潜在的缺陷已经被发现和修补过了。
无论在发布前已经进行过多少次手动测试，我们最终还是会依靠自动化：基础设施允许我们完成控制条件下的转出，而我们的集群免疫系统对于回归问题的监测也减少了对顾客产生负面影响的风险。
最后，当特性呈现在顾客眼前的时候，我们会等待A/B分裂实验系统的实验结果，并倾听社区管理和客户服务团队的反馈。当反馈开始增加的时候——通常是马上，我们已经是准备好了的。我们已经特地为报告的缺陷和问题留出了快速反应的工程时间，也为让特性更加有趣的一些小变化做好了准备。
我们绝非完美：一直努力迅速向用户传递价值但是QA资源有限，也经常在生产过程中引入缺陷并且提交不完美的功能。但重要的是，我们能马上就知道用户想让我们做什么，然后一直迭代。</description>
    </item>
    
  </channel>
</rss>